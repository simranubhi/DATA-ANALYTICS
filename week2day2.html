                                                                         ---- WeeK 2 (DAY-2) ----

1. Data Frames and Tibbles
Data frames are the most common way to store tabular data in R, consisting of rows and columns.
They can hold different data types (numeric, character, etc.) in each column.
Tibbles are a modern version of data frames from the tibble package, designed to print cleaner output and behave consistently with the tidyverse.
Tibbles don’t change column names or types automatically, making them more predictable and readable.
They are preferred when working with large datasets and complex pipelines.

-- Code --
df <- data.frame(ID = c(1, 2), Name = c("A", "B"))
tb <- tibble::tibble(ID = c(1, 2), Name = c("A", "B"))


 2. Reading/Writing CSV, Excel, and Text Files
Data in real-world projects usually comes from external files like CSVs or Excel sheets.
R supports reading files using read.csv() and Excel files using read_excel() (via readxl package).
You can also export data frames back to files using write.csv() or write_xlsx().
These functions make it easy to bring data into R for analysis and share results with others.
Reading text files, or tab-delimited data, is handled with read.table() or read.delim().

-- Code --
read.csv("file.csv")
write.csv(data_frame, "output.csv")

For Excel:
install.packages("readxl")
library(readxl)
read_excel("file.xlsx")

To write Excel:
install.packages("writexl")
library(writexl)
write_xlsx(data_frame, "output.xlsx")


3. Data Exploration
Before analyzing data, it's important to explore and understand its structure and contents.
Functions like head(), dim(), str(), and summary() are used to inspect rows, columns, data types, and basic statistics.
Exploration helps identify missing values, unusual patterns, and variable types.
It provides a quick snapshot of how clean or messy your dataset is.
This is a key first step before any transformation or modeling.

-- Code --
head(data) #review rows
dim(data) #review columns
names(data) #review variable names
summary(data)
str(data)


4. Data Cleaning Basics
Data cleaning involves removing errors, fixing inconsistencies, and preparing data for analysis.
It includes handling missing values, correcting data types, and removing duplicates.
R provides functions like is.na(), na.omit(), and duplicated() to assist in cleaning.
Proper cleaning ensures the quality and accuracy of analysis.
Without this step, insights drawn from data may be unreliable or misleading.

5. Handling Missing Values
Missing data is common in real-world datasets, and must be addressed carefully.
You can detect missing values using is.na() and decide whether to drop or impute them.
na.omit() removes rows with NAs, while tidyr::fill() can propagate non-missing values.
How you handle missing values depends on the context and the importance of the missing data.
This is crucial for maintaining data integrity and preventing errors during analysis.

-- Code --
is.na(df)
df <- tidyr::fill(df, column_name, .direction = "updown")

6. Filtering, Selecting, and Renaming Columns
Using the dplyr package, you can filter rows (filter()), select specific columns (select()), and rename columns (rename()).
This helps you focus only on relevant parts of the dataset for your task.
For example, filtering students with marks > 75, or selecting only Name and Age columns.
Renaming columns improves readability and consistency in reports or code.
These operations are basic but powerful tools for shaping data.

-- Code --
filter(df, Age > 18)
select(df, Name, Age)
rename(df, FullName = Name)

7. Type Conversions and String Handling
Type conversion functions like as.numeric(), as.character(), and as.factor() ensure data is in the correct format.
String handling includes modifying and inspecting text using functions like tolower(), toupper(), and nchar().
These are useful when dealing with messy or imported data where formats are inconsistent.
Proper formatting is important for analysis, plotting, and machine learning workflows.
String operations also help clean labels, extract values, or format output.

-- Code --
Type Conversions --> as.numeric(), as.character(), as.factor()
String Functions --> tolower("TEXT"), toupper("text"), nchar("string")

8. Data Wrangling with dplyr and tidyr
Wrangling refers to transforming raw data into a usable format.
dplyr offers functions like mutate() to create new variables and arrange() to sort data.

-- Code --
Mutating --> mutate(df, AgeSquared = Age^2)
Grouping and Summarizing --> group_by(df, Department) %>%
                             summarise(AvgSalary = mean(Salary, na.rm = TRUE))



--- CODING PRACTICE ---

# -----------------------------------------------
# Topics: pivot_longer, pivot_wider, melt, spread
# -----------------------------------------------

# Load the required package for modern data reshaping
library(tidyr)

# Creating a sample wide-format data frame with student test scores
st_test1 <- data.frame(
  id = c(1, 2, 3), 
  name = c("Alice", "Bob", "John"),
  test1 = c(95, 91, 85), 
  test2 = c(98, 80, 87), 
  test3 = c(92, 93, 90)
)

# ---- Reshape from WIDE to LONG using pivot_longer() ----
# This transforms multiple test columns into a single 'test' column
# and their corresponding values into a 'score' column
st_test2 <- pivot_longer(
  st_test1, 
  cols = starts_with("test"),   # Select columns starting with "test"
  names_to = "test",            # Create a new column called 'test' with names of the original columns
  values_to = "score"           # Create a new column called 'score' with corresponding values
)
print(st_test2)

# ---- Install necessary packages ----
# 'stringi' and 'reshape2' are required for legacy reshaping methods
install.packages("stringi")     # (Only run once)
install.packages("reshape2")    # (Only run once)

# Load the packages
library(reshape2)
library(stringi)

# ---- Reshape from WIDE to LONG using melt() [older method] ----
# melt() works similarly to pivot_longer(), but is part of the older reshape2 package
st_test2 <- melt(
  st_test1, 
  id.vars = c("id", "name"),    # Keep 'id' and 'name' as identifiers
  variable.name = "test",       # Name of new column to store original column names
  value.name = "score"          # Name of new column to store corresponding values
)
print(st_test2)

# ---- Reshape from LONG back to WIDE using pivot_wider() ----
# This spreads 'test' values into new columns, with scores filled in
st_test3 <- st_test2 %>% pivot_wider(
  names_from = test,            # Use values in 'test' column as new column names
  values_from = score           # Fill values from 'score' column
)
print(st_test3)

# ---- Alternate method: Reshape LONG to WIDE using spread() [older method] ----
# spread() is the older version of pivot_wider(), now less recommended
st_test3 <- spread(
  st_test2, 
  test,                         # Column to become new column names
  score                         # Column with values to fill in
)
print(st_test3)

# ---- Extended Real-life Example: Monthly Expenses ----

# Creating long-format monthly expense data for 5 years (2021–2025)
st_test4 <- data.frame(
  Year = rep(2021:2025, each = 12),       # Repeat each year 12 times
  month = rep(month.abb, times = 5),      # Repeat all months 5 times
  expenses = 101:160                      # Dummy expense values (60 total)
)

# Convert to WIDE format: one row per year, months as columns
wide_data <- pivot_wider(
  st_test4, 
  names_from = month, 
  values_from = expenses
)
print(wide_data)

# Convert back to LONG format: one row per year-month combination
long_data <- pivot_longer(
  wide_data,
  cols = -Year,                          # All columns except 'Year' are months
  names_to = "month",                    # Store month names in 'month' column
  values_to = "expenses"                 # Store values in 'expenses' column
)
print(long_data)


                                                  ----------------------------------------------------------------------------------
